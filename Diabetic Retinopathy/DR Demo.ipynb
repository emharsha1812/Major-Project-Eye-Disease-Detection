{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e2cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ac87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e68869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8755 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Generators\n",
    "train_batches = train_datagen.flow_from_directory(\n",
    "    'reduceddata/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6673ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1840 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_batches = ImageDataGenerator(rescale=1.0/255.0).flow_from_directory(\n",
    "    'reduceddata/valid',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=30,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4306701",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Large(weights='imagenet', include_top=False,input_shape=(224,224,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d20a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model\n",
    "new_model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dbe55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze some layers for fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd6ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "new_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "805d5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for model saving and early stopping\n",
    "checkpointer = ModelCheckpoint(filepath='drdetection.hdf5', save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "438/438 [==============================] - 150s 295ms/step - loss: 1.1422 - accuracy: 0.6688 - val_loss: 1.2371 - val_accuracy: 0.2543\n",
      "Epoch 2/30\n",
      "438/438 [==============================] - 122s 278ms/step - loss: 0.8778 - accuracy: 0.7374 - val_loss: 1.3798 - val_accuracy: 0.7342\n",
      "Epoch 3/30\n",
      "438/438 [==============================] - 119s 270ms/step - loss: 0.8695 - accuracy: 0.7383 - val_loss: 3.1478 - val_accuracy: 0.7337\n",
      "Epoch 4/30\n",
      "438/438 [==============================] - 112s 256ms/step - loss: 0.8703 - accuracy: 0.7383 - val_loss: 3.5860 - val_accuracy: 0.1511\n",
      "Epoch 5/30\n",
      "368/438 [========================>.....] - ETA: 16s - loss: 0.8679 - accuracy: 0.7368"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = new_model.fit(\n",
    "    train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00035bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "majorproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
