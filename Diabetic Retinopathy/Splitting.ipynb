{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6901295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and subfolders created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path to the eyepacs_preprocess directory containing images\n",
    "image_dir = 'eyepacs_preprocess'\n",
    "\n",
    "# Path to the CSV file containing image labels\n",
    "csv_file = 'labels.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Split the data into train and test sets (80:20)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['level'])\n",
    "\n",
    "# Define the paths for the train and test directories\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Automatically create subfolders 'DR' and 'No_DR' within train and test directories\n",
    "for directory in [train_dir, test_dir]:\n",
    "    for class_name in ['DR', 'No_DR']:\n",
    "        os.makedirs(os.path.join(directory, class_name), exist_ok=True)\n",
    "\n",
    "# Move images to the appropriate subfolders based on their labels\n",
    "for index, row in train_df.iterrows():\n",
    "    image_name = row['image'] + '.jpeg'  # Append '.png' to the image name\n",
    "    label = row['level']\n",
    "    src_path = os.path.join(image_dir, image_name)\n",
    "    dest_dir = os.path.join(train_dir, 'DR') if label != 0 else os.path.join(train_dir, 'No_DR')\n",
    "    shutil.copy(src_path, os.path.join(dest_dir, image_name))\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    image_name = row['image'] + '.jpeg'  # Append '.png' to the image name\n",
    "    label = row['level']\n",
    "    src_path = os.path.join(image_dir, image_name)\n",
    "    dest_dir = os.path.join(test_dir, 'DR') if label != 0 else os.path.join(test_dir, 'No_DR')\n",
    "    shutil.copy(src_path, os.path.join(dest_dir, image_name))\n",
    "\n",
    "print(\"Data split and subfolders created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf36db20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have different dimensions.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to the directory containing the images\n",
    "image_dir = 'eyepacs_preprocess'\n",
    "\n",
    "# Initialize variables to store dimensions of the first image\n",
    "first_image_width = None\n",
    "first_image_height = None\n",
    "\n",
    "# Flag to indicate if all images have the same dimensions\n",
    "all_images_have_same_dimensions = True\n",
    "\n",
    "# Loop through all images in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpeg') or filename.endswith('.jpg'):\n",
    "        # Open the image using Pillow\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Get the dimensions of the current image\n",
    "        current_width, current_height = image.size\n",
    "\n",
    "        # If this is the first image, store its dimensions\n",
    "        if first_image_width is None and first_image_height is None:\n",
    "            first_image_width = current_width\n",
    "            first_image_height = current_height\n",
    "        else:\n",
    "            # Compare dimensions with the first image\n",
    "            if current_width != first_image_width or current_height != first_image_height:\n",
    "                all_images_have_same_dimensions = False\n",
    "                break  # No need to check further\n",
    "\n",
    "# Check the result\n",
    "if all_images_have_same_dimensions:\n",
    "    print(\"All images have the same dimensions.\")\n",
    "    print(f\"Dimensions: {first_image_width} x {first_image_height}\")\n",
    "else:\n",
    "    print(\"Images have different dimensions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "200c4d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_27908\\3327224812.py:23: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_image = image.resize((target_width, target_height), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have been resized to 224x224 pixels and saved to eyepacs_preprocess_resized\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to the directory containing the images\n",
    "image_dir = 'eyepacs_preprocess'\n",
    "\n",
    "# Create a directory to store resized images\n",
    "output_dir = 'eyepacs_preprocess_resized'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Target dimensions\n",
    "target_width = 224\n",
    "target_height = 224\n",
    "\n",
    "# Loop through all images in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpeg') or filename.endswith('.jpg'):\n",
    "        # Open the image using Pillow\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Resize the image to the target dimensions\n",
    "        resized_image = image.resize((target_width, target_height), Image.ANTIALIAS)\n",
    "\n",
    "        # Save the resized image to the output directory\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        resized_image.save(output_path)\n",
    "\n",
    "print(\"All images have been resized to 224x224 pixels and saved to\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5e556de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7445 images from each class copied to smaller balanced train dataset.\n",
      "1861 images from each class copied to smaller balanced test dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths to the original train and test directories\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Create new directories for the smaller balanced train and test sets\n",
    "small_balanced_train_dir = 'small_balanced_train'\n",
    "small_balanced_test_dir = 'small_balanced_test'\n",
    "\n",
    "# Create the smaller balanced train and test directories if they don't exist\n",
    "os.makedirs(small_balanced_train_dir, exist_ok=True)\n",
    "os.makedirs(small_balanced_test_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy images from the source to destination\n",
    "def copy_images(source_dir, destination_dir, num_images):\n",
    "    image_files = os.listdir(source_dir)\n",
    "    random.shuffle(image_files)  # Shuffle the images randomly\n",
    "    \n",
    "    for i, image in enumerate(image_files):\n",
    "        if i >= num_images:\n",
    "            break  # Stop copying once the desired number is reached\n",
    "        \n",
    "        src_path = os.path.join(source_dir, image)\n",
    "        dest_path = os.path.join(destination_dir, image)\n",
    "        \n",
    "        # Ensure that the destination directory exists\n",
    "        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "        \n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Count the minimum number of images between 'DR' and 'No_DR' subfolders in the train dataset\n",
    "num_images_in_DR_train = len(os.listdir(os.path.join(train_dir, 'DR')))\n",
    "num_images_in_No_DR_train = len(os.listdir(os.path.join(train_dir, 'No_DR')))\n",
    "min_images_train = min(num_images_in_DR_train, num_images_in_No_DR_train)\n",
    "\n",
    "# Count the minimum number of images between 'DR' and 'No_DR' subfolders in the test dataset\n",
    "num_images_in_DR_test = len(os.listdir(os.path.join(test_dir, 'DR')))\n",
    "num_images_in_No_DR_test = len(os.listdir(os.path.join(test_dir, 'No_DR')))\n",
    "min_images_test = min(num_images_in_DR_test, num_images_in_No_DR_test)\n",
    "\n",
    "# Copy the same number of random images from the 'DR' and 'No_DR' subfolders in both train and test\n",
    "copy_images(os.path.join(train_dir, 'DR'), os.path.join(small_balanced_train_dir, 'DR'), min_images_train)\n",
    "copy_images(os.path.join(train_dir, 'No_DR'), os.path.join(small_balanced_train_dir, 'No_DR'), min_images_train)\n",
    "copy_images(os.path.join(test_dir, 'DR'), os.path.join(small_balanced_test_dir, 'DR'), min_images_test)\n",
    "copy_images(os.path.join(test_dir, 'No_DR'), os.path.join(small_balanced_test_dir, 'No_DR'), min_images_test)\n",
    "\n",
    "print(f\"{min_images_train} images from each class copied to smaller balanced train dataset.\")\n",
    "print(f\"{min_images_test} images from each class copied to smaller balanced test dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d800cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0% of training data copied to the validation dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths to the original train and test directories\n",
    "train_dir = 'small_balanced_train'  # Updated to use the small balanced train dataset\n",
    "valid_dir = 'valid'  # New directory for the validation dataset\n",
    "\n",
    "# Create the validation directory if it doesn't exist\n",
    "os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy a specified percentage of random images from the source to destination\n",
    "def copy_percentage_images(source_dir, destination_dir, percentage):\n",
    "    image_files = os.listdir(source_dir)\n",
    "    random.shuffle(image_files)  # Shuffle the images randomly\n",
    "    num_images = int(len(image_files) * percentage)\n",
    "    \n",
    "    for i, image in enumerate(image_files):\n",
    "        if i >= num_images:\n",
    "            break  # Stop copying once the desired number is reached\n",
    "        \n",
    "        src_path = os.path.join(source_dir, image)\n",
    "        dest_path = os.path.join(destination_dir, image)\n",
    "        \n",
    "        # Ensure that the destination directory exists\n",
    "        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "        \n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Set the desired percentage of training data to be used for validation\n",
    "validation_percentage = 0.2  # Adjust this percentage as needed\n",
    "\n",
    "# Copy the specified percentage of random images from both 'DR' and 'No_DR' subfolders in the training dataset\n",
    "copy_percentage_images(os.path.join(train_dir, 'DR'), os.path.join(valid_dir, 'DR'), validation_percentage)\n",
    "copy_percentage_images(os.path.join(train_dir, 'No_DR'), os.path.join(valid_dir, 'No_DR'), validation_percentage)\n",
    "\n",
    "print(f\"{validation_percentage * 100}% of training data copied to the validation dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c86adac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0% of training data moved to the validation dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Paths to the original train and validation directories\n",
    "train_dir = 'small_balanced_train'  # Updated to use the small balanced train dataset\n",
    "valid_dir = 'valid'  # New directory for the validation dataset\n",
    "\n",
    "# Create the validation directory if it doesn't exist\n",
    "os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "# Function to move a specified percentage of random images from the source to destination\n",
    "def move_percentage_images(source_dir, destination_dir, percentage):\n",
    "    image_files = os.listdir(source_dir)\n",
    "    random.shuffle(image_files)  # Shuffle the images randomly\n",
    "    num_images = int(len(image_files) * percentage)\n",
    "    \n",
    "    for i, image in enumerate(image_files):\n",
    "        if i >= num_images:\n",
    "            break  # Stop moving once the desired number is reached\n",
    "        \n",
    "        src_path = os.path.join(source_dir, image)\n",
    "        dest_path = os.path.join(destination_dir, image)\n",
    "        \n",
    "        # Ensure that the destination directory exists\n",
    "        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "        \n",
    "        shutil.move(src_path, dest_path)\n",
    "\n",
    "# Set the desired percentage of training data to be used for validation\n",
    "validation_percentage = 0.2  # Adjust this percentage as needed\n",
    "\n",
    "# Move the specified percentage of random images from both 'DR' and 'No_DR' subfolders in the training dataset\n",
    "move_percentage_images(os.path.join(train_dir, 'DR'), os.path.join(valid_dir, 'DR'), validation_percentage)\n",
    "move_percentage_images(os.path.join(train_dir, 'No_DR'), os.path.join(valid_dir, 'No_DR'), validation_percentage)\n",
    "\n",
    "print(f\"{validation_percentage * 100}% of training data moved to the validation dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de9d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
